{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d63ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import os\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "from pygame import mixer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837bf73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽어오기\n",
    "path_dir1 = './nomask/'\n",
    "path_dir2 = './mask/'\n",
    " \n",
    "file_list1 = os.listdir(path_dir1) # path에 존재하는 파일 목록 가져오기\n",
    "file_list2 = os.listdir(path_dir2)\n",
    " \n",
    "file_list1_num = len(file_list1)\n",
    "file_list2_num = len(file_list2)\n",
    " \n",
    "file_num = file_list1_num + file_list2_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081cdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리\n",
    "num = 0;\n",
    "all_img = np.float32(np.zeros((file_num, 224, 224, 3))) \n",
    "all_label = np.float64(np.zeros((file_num, 1)))\n",
    " \n",
    "for img_name in file_list1:\n",
    "    img_path = path_dir1+img_name\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    all_img[num, :, :, :] = x\n",
    "    \n",
    "    all_label[num] = 0 # nomask\n",
    "    num = num + 1\n",
    " \n",
    "for img_name in file_list2:\n",
    "    img_path = path_dir2+img_name\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    all_img[num, :, :, :] = x\n",
    "    \n",
    "    all_label[num] = 1 # mask\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 섞기(적절하게 훈련되게 하기 위함) \n",
    "n_elem = all_label.shape[0]\n",
    "indices = np.random.choice(n_elem, size=n_elem, replace=False)\n",
    " \n",
    "all_label = all_label[indices]\n",
    "all_img = all_img[indices]\n",
    " \n",
    "    \n",
    "# 훈련셋 테스트셋 분할\n",
    "num_train = int(np.round(all_label.shape[0]*0.8))\n",
    "num_test = int(np.round(all_label.shape[0]*0.2))\n",
    " \n",
    "train_img = all_img[0:num_train, :, :, :]\n",
    "test_img = all_img[num_train:, :, :, :] \n",
    " \n",
    "train_label = all_label[0:num_train]\n",
    "test_label = all_label[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df54badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    " \n",
    "base_model = ResNet50(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)\n",
    "base_model.trainable = False\n",
    " \n",
    "flatten_layer = Flatten()\n",
    "dense_layer1 = Dense(128, activation='relu')\n",
    "bn_layer1 = BatchNormalization()\n",
    "dense_layer2 = Dense(1, activation=tf.nn.sigmoid)\n",
    " \n",
    "model = Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer1,\n",
    "        bn_layer1,\n",
    "        dense_layer2,\n",
    "        ])\n",
    " \n",
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "start = datetime.datetime.now()\n",
    "hist = model.fit(train_img, train_label, epochs=10, batch_size=16, validation_data = (test_img, test_label))\n",
    "end = datetime.datetime.now()\n",
    "time = end - start\n",
    "print(\"학습시간: \", time) \n",
    "\n",
    "\n",
    "#모델 저장\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ce162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 요약 정보 출력\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "base_model.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 시각화\n",
    "plot_model(model, to_file='model_shapes.png')\n",
    "plot_model(model, to_file='model_shapes.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12961a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과 그래프\n",
    "plt.plot(hist.history['acc'], label='acc')\n",
    "plt.plot(hist.history['val_acc'], label='val_acc')\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(\"train_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미착용자 감지될 경우 알림음 재생\n",
    "mixer.init()\n",
    "sound = mixer.Sound('maskon.wav')\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미착용자 감지될 경우 슬랙 메시지 전송\n",
    "def send_message(msg):\n",
    "    url='https://hooks.slack.com/services/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'\n",
    "    data = {'text':msg}\n",
    "    resp = requests.post(url=url, json=data)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560519f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹캠 실행\n",
    "webcam = cv2.VideoCapture(0)\n",
    "alarm = 0\n",
    "count = 0 \n",
    " \n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹캠 프레임당 루프\n",
    "while webcam.isOpened():\n",
    " \n",
    "    # 웹캠에서 프레임 읽어오기\n",
    "    status, frame = webcam.read()\n",
    "    \n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    " \n",
    "    # 얼굴 감지\n",
    "    face, confidence = cv.detect_face(frame)\n",
    " \n",
    "    # 감지된 얼굴에 루프\n",
    "    for idx, f in enumerate(face):\n",
    "        \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "        \n",
    "        if 0 <= startX <= frame.shape[1] and 0 <= endX <= frame.shape[1] and 0 <= startY <= frame.shape[0] and 0 <= endY <= frame.shape[0]:\n",
    "            \n",
    "            face_region = frame[startY:endY, startX:endX]\n",
    "            \n",
    "            face_region1 = cv2.resize(face_region, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            x = img_to_array(face_region1)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            \n",
    "            prediction = model.predict(x)\n",
    " \n",
    "            if prediction < 0.5: # 마스크 미착용으로 판별되면,\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,0,255), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"No Mask ({:.2f}%)\".format((1 - prediction[0][0])*100)\n",
    "                cv2.putText(frame, text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "                alarm += 1\n",
    "                count += 1\n",
    "                if alarm == 15:\n",
    "                    sound.play()\n",
    "                    alarm = 0\n",
    "                if count == 50:\n",
    "                    send_message('마스크 미착용자 감지')\n",
    "                    count = 0\n",
    "\n",
    "                \n",
    "            else: # 마스크 착용으로 판별되면\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"Mask ({:.2f}%)\".format(prediction[0][0]*100)\n",
    "                cv2.putText(frame, text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                alarm = 0\n",
    "                count = 0\n",
    "    \n",
    "    # 결과 출력\n",
    "    cv2.imshow(\"mask nomask classify\", frame)\n",
    " \n",
    "    # Q키 누르면 프로그램 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c242fda8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
